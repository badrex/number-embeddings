{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/badr/embeddings/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Any, Tuple, Generator\n",
    "import json\n",
    "\n",
    "# utilities\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# data processing\n",
    "from scipy import stats\n",
    "import faiss \n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eight'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a module for lexicalizing numbers (e.g. 8 -> eight)\")\n",
    "import inflect\n",
    "number_lexicalizer = inflect.engine()\n",
    "\n",
    "\n",
    "# try it out \n",
    "number_lexicalizer.number_to_words(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_evaluate = {\n",
    "    \"miniLM-L6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    # \"miniLM-L12\": \"sentence-transformers/all-MiniLM-L12-v2\",\n",
    "    # \"mxbai\": \"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "    # \"jina-base\": \"jinaai/jina-embeddings-v2-base-en\",\n",
    "    # \"jina-small\": \"jinaai/jina-embeddings-v2-small-en\",\n",
    "    # \"jina-code\": \"jinaai/jina-embeddings-v2-base-code\",\n",
    "    # \"LaBSE\": \"sentence-transformers/LaBSE\",\n",
    "    #\"textCLIP\": \"sentence-transformers/clip-ViT-B-32\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_models = defaultdict()\n",
    "\n",
    "for m in models_to_evaluate:\n",
    "    encoder_models[m] = SentenceTransformer(\n",
    "        models_to_evaluate[m], \n",
    "        trust_remote_code=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file and load the JSON data\n",
    "file_path = './restaurants.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    restaurants_data = json.load(file)\n",
    "\n",
    "restaurant_documents = [\n",
    "    restaurant['description'] for restaurant in restaurants_data\n",
    "]\n",
    "\n",
    "#len(restaurants_data), len(restaurant_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_queries = [\n",
    "    (\"Show me restaurants rated above {} stars\", \">=\"),\n",
    "    (\"I'm looking for restaurants with at least {} stars\", \">=\"),\n",
    "    (\"Suggest restaurants rated {} stars or higher\", \">=\"),\n",
    "    (\"Find restaurants with more than {} stars\", \">=\"),\n",
    "    (\"List restaurants rated {} stars and above\", \">=\"),\n",
    "    (\"Recommend restaurants rated with {} stars or more\", \">=\"),\n",
    "    (\"Restaurants with a minimum of {} stars\", \">=\"),\n",
    "    (\"Show me restaurants rated above {} stars\", \">\"),\n",
    "    (\"Restaurants rated no less than {} stars\", \">=\"),\n",
    "    (\"Find Restaurants with star ratings above {} stars\", \">=\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_sample_query(\n",
    "    query: str,\n",
    "    target_number: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Function to generate a test sample query. \n",
    "    \"\"\"\n",
    "\n",
    "    # check if the target number is 10 and the operator is \">\"\n",
    "    if target_number >= 10 or target_number <= 0:\n",
    "        raise ValueError(\"target_number should be in the range [1, 10].\")\n",
    "    \n",
    "    \n",
    "    # create the query sentence\n",
    "    # for example, query = \"Show me restaurants rated above {} stars\" and \n",
    "    # target_number = 5 --> query = \"Show me restaurants rated above 5 stars\"\n",
    "    query_sent = query.format(target_number)\n",
    "\n",
    "    # lexicalize the target number\n",
    "    target_number_lex = number_lexicalizer.number_to_words(target_number)\n",
    "\n",
    "    # create the query sentence with lexicalized number\n",
    "    # above example, query_lex = \"Show me restaurants rated above five stars\"\n",
    "    query_sent_lex = query.format(target_number_lex)\n",
    "    \n",
    "    return {\n",
    "        \"numeral\": query_sent,\n",
    "        \"lexical\": query_sent_lex,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numeral': 'Show me restaurants rated above 5 stars',\n",
       " 'lexical': 'Show me restaurants rated above five stars'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets test generate_test_sample_query\n",
    "generate_test_sample_query(\n",
    "    query=restaurant_queries[0][0], \n",
    "    target_number=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_sample_candidates(\n",
    "    operator: str, \n",
    "    candidates: List[str],\n",
    "    target_number: int,  \n",
    "    max_items_to_retrieve:int, \n",
    "    items_to_retrieve:int = 1,\n",
    "    random_seed: int=42) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate a test sample for the item retrieval task.\n",
    "    \"\"\"\n",
    "    # handle edge cases\n",
    "    if operator not in [\">\", \">=\", \"<\", \"<=\"]:\n",
    "        raise ValueError(\"Operator must be one of ['>', '>=', '<', '<=']\")\n",
    "    \n",
    "    if max_items_to_retrieve > len(candidates):\n",
    "        err_msg = \"max_items_to_retrieve can't be greater than num of candidates\"\n",
    "        raise ValueError(err_msg)\n",
    "    \n",
    "    # ensure items_to_retrieve is a valide value \n",
    "    if items_to_retrieve < 1:\n",
    "        raise ValueError(\"items_to_retrieve must be greater than 0.\")\n",
    "    \n",
    "    # ensure the target items to retrieve is less than the max items to retrieve\n",
    "    if items_to_retrieve > max_items_to_retrieve:\n",
    "        raise ValueError(\"items_to_retrieve <= max_items_to_retrieve.\")\n",
    "      \n",
    "    # set random seed for reproducibility\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # associate a value for each search item\n",
    "    # where only N of those are equal to or higher than the target number\n",
    "    #items_to_retrieve = np.random.randint(1, max_items_to_retrieve)\n",
    "\n",
    "    # adjust target number based on operator\n",
    "    # comment this for now \n",
    "    # let us be genrous and consider above n is a number that includes n\n",
    "    #target_number = target_number + 1 if operator == \">\" else target_number\n",
    "\n",
    "    hit_items = np.random.randint(target_number, 11, items_to_retrieve)\n",
    "    miss_items = np.random.randint(\n",
    "        1, target_number, len(candidates) - items_to_retrieve\n",
    "    )\n",
    "\n",
    "    # list of number for each item\n",
    "    items_numbers: List[int] = np.concatenate([hit_items, miss_items])\n",
    "\n",
    "    # define a boolean list to check if the rating is hit (should be returned)\n",
    "    relevance_scores: List[int] = [\n",
    "        0 if rating < target_number else 1 for rating in items_numbers\n",
    "    ]\n",
    "\n",
    "    # ensure correct number of relevant items\n",
    "    if np.sum(relevance_scores) != items_to_retrieve:\n",
    "        print(relevance_scores)\n",
    "        raise ValueError(\"Relevance score != equal to max_items_to_retrieve!\")    \n",
    "\n",
    "\n",
    "    candidates_sent = [\n",
    "        candidate.format(num)\n",
    "        for candidate, num in zip(candidates, items_numbers)\n",
    "    ]\n",
    "\n",
    "    candidates_sent_lex = [\n",
    "        candidate.format(number_lexicalizer.number_to_words(num))\n",
    "        for candidate, num in zip(candidates, items_numbers)\n",
    "    ]\n",
    "    \n",
    "    # construct the result\n",
    "    return {\n",
    "        \"candidates\": {\n",
    "            \"numeral\": candidates_sent,\n",
    "            \"lexical\": candidates_sent_lex\n",
    "        },\n",
    "        \"relevance_scores\": relevance_scores\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Bernardin, a seafood restaurant, has a 8 star rating.                                   ✔️              \n",
      "Alinea, specializing in molecular gastronomy, is rated 1 stars.                                            \n",
      "Joe's Place, a classic American diner, received a 3 star rating from customers.                            \n",
      "Noma, featuring New Nordic cuisine, currently holds a 3 star rating.                                       \n",
      "Luigi's Pizzeria, serving traditional Italian pies, has been given 4 stars by diners.                      \n",
      "El Celler de Can Roca, offering modern Spanish dishes, maintains a 1 star rating.                          \n",
      "Sukiyabashi Jiro, a sushi restaurant, has received 1 stars.                                                \n",
      "Burger Bonanza, a fast-food burger joint, averages 3 stars across its locations.                           \n",
      "Osteria Francescana, presenting contemporary Italian cuisine, holds a 2 star rating.                       \n",
      "Green Fields, a farm-to-table restaurant, has cultivated a 3 star rating.                                  \n"
     ]
    }
   ],
   "source": [
    "# test generate_test_sample_candidates\n",
    "test_samples = generate_test_sample_candidates(\n",
    "    operator=\">=\",\n",
    "    candidates=restaurant_documents[:10],\n",
    "    target_number=5,\n",
    "    max_items_to_retrieve=10,\n",
    "    #items_to_retrieve=1\n",
    ")\n",
    "\n",
    "for case, rel in zip(test_samples[\"candidates\"][\"numeral\"], test_samples[\"relevance_scores\"]):\n",
    "    print(f\"{case:90} {'✔️' if rel == 1 else '':15} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_sample(\n",
    "    query: str,\n",
    "    candidates: List[str],\n",
    "    operator: str,\n",
    "    target_number: int,\n",
    "    max_items_to_retrieve: int,\n",
    "    items_to_retrieve: int = 1,\n",
    "    random_seed: int = 42) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate a test sample for the item retrieval task.\n",
    "    \"\"\"\n",
    "    # generate the query\n",
    "    query_sample = generate_test_sample_query(query, target_number)\n",
    "    \n",
    "    # generate the candidates\n",
    "    candidates_sample = generate_test_sample_candidates(\n",
    "        operator=operator,\n",
    "        candidates=candidates,\n",
    "        target_number=target_number,\n",
    "        max_items_to_retrieve=max_items_to_retrieve,\n",
    "        items_to_retrieve=items_to_retrieve,\n",
    "        random_seed=random_seed\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"query\": query_sample,\n",
    "        \"candidates\": candidates_sample['candidates'],\n",
    "        \"relevance_scores\": candidates_sample['relevance_scores']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Show me restaurants rated above 5 stars\n",
      "\n",
      "Le Bernardin, a seafood restaurant, has a 8 star rating.                                   ✔️              \n",
      "Alinea, specializing in molecular gastronomy, is rated 9 stars.                            ✔️              \n",
      "Joe's Place, a classic American diner, received a 3 star rating from customers.                            \n",
      "Noma, featuring New Nordic cuisine, currently holds a 3 star rating.                                       \n",
      "Luigi's Pizzeria, serving traditional Italian pies, has been given 4 stars by diners.                      \n",
      "El Celler de Can Roca, offering modern Spanish dishes, maintains a 1 star rating.                          \n",
      "Sukiyabashi Jiro, a sushi restaurant, has received 1 stars.                                                \n",
      "Burger Bonanza, a fast-food burger joint, averages 3 stars across its locations.                           \n",
      "Osteria Francescana, presenting contemporary Italian cuisine, holds a 2 star rating.                       \n",
      "Green Fields, a farm-to-table restaurant, has cultivated a 3 star rating.                                  \n"
     ]
    }
   ],
   "source": [
    "# try out test sample generation\n",
    "full_test_sample = generate_test_sample(\n",
    "    query=\"Show me restaurants rated above {} stars\", \n",
    "    candidates=restaurant_documents[:10],  \n",
    "    operator=\">=\",\n",
    "    target_number=5,\n",
    "    max_items_to_retrieve=10,\n",
    "    items_to_retrieve=2,\n",
    "    random_seed=42\n",
    "\n",
    ")\n",
    "\n",
    "print(f\"Query: {full_test_sample['query']['numeral']}\", end=\"\\n\\n\")\n",
    "\n",
    "for case, rel in zip(full_test_sample[\"candidates\"][\"numeral\"], full_test_sample[\"relevance_scores\"]):\n",
    "    print(f\"{case:90} {'✔️' if rel == 1 else '':15} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate full test samples\n",
    "\n",
    "test_cases = []\n",
    "\n",
    "# iterate over each query templates and generate test samples\n",
    "for query, operator in restaurant_queries:\n",
    "    for _ in range(10):\n",
    "\n",
    "        # sample a target number \n",
    "        # if oeprator is >, then we need to sample a number between 6 and 10\n",
    "        if operator == \">\" or operator == \">=\":\n",
    "            target_number = np.random.randint(5, 11)\n",
    "        else:\n",
    "            target_number = np.random.randint(1, 6)\n",
    "\n",
    "        # get items to retrieve\n",
    "        max_items_to_retrieve=10\n",
    "        items_to_retrieve = np.random.randint(1, max_items_to_retrieve)\n",
    "\n",
    "\n",
    "        test_sample = generate_test_sample(\n",
    "            query=query,\n",
    "            candidates=restaurant_documents,\n",
    "            operator=operator,\n",
    "            target_number=target_number,\n",
    "            max_items_to_retrieve=max_items_to_retrieve,\n",
    "            items_to_retrieve=items_to_retrieve,\n",
    "            random_seed=42\n",
    "        )\n",
    "        \n",
    "        test_cases.append(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show me restaurants rated above 8 stars\n",
      "Le Bernardin, a seafood restaurant, has a 10 star rating.                                  ✔️              \n",
      "Alinea, specializing in molecular gastronomy, is rated 8 stars.                            ✔️              \n",
      "Joe's Place, a classic American diner, received a 10 star rating from customers.           ✔️              \n",
      "Noma, featuring New Nordic cuisine, currently holds a 10 star rating.                      ✔️              \n",
      "Luigi's Pizzeria, serving traditional Italian pies, has been given 8 stars by diners.      ✔️              \n",
      "El Celler de Can Roca, offering modern Spanish dishes, maintains a 8 star rating.          ✔️              \n",
      "Sukiyabashi Jiro, a sushi restaurant, has received 10 stars.                               ✔️              \n",
      "Burger Bonanza, a fast-food burger joint, averages 9 stars across its locations.           ✔️              \n",
      "Osteria Francescana, presenting contemporary Italian cuisine, holds a 10 star rating.      ✔️              \n",
      "Green Fields, a farm-to-table restaurant, has cultivated a 7 star rating.                                  \n",
      "Sushi Saito, a renowned sushi establishment, boasts a 3 star rating.                                       \n",
      "The Fat Duck, known for its innovative dishes, has earned 3 stars.                                         \n",
      "Eleven Madison Park, serving contemporary American cuisine, is rated 5 stars.                              \n",
      "Central, showcasing Peruvian biodiversity, has received a 4 star rating.                                   \n",
      "Gaggan, offering progressive Indian cuisine, holds a 3 star rating.                                        \n",
      "D.O.M., featuring Brazilian ingredients, has been awarded 6 stars.                                         \n",
      "Pujol, a modern Mexican restaurant, maintains a 5 star rating.                                             \n",
      "Steirereck, serving contemporary Austrian dishes, has earned 2 stars.                                      \n",
      "Narisawa, known for innovative Satoyama cuisine, holds a 4 star rating.                                    \n",
      "Attica, showcasing Australian ingredients, has received 6 stars from diners.                               \n",
      "Quintonil, a modern Mexican eatery, has been given 6 stars by critics.                                     \n",
      "Mirazur, offering Mediterranean flavors, boasts a 2 star rating.                                           \n",
      "Asador Etxebarri, famous for its grilled dishes, maintains 4 stars.                                        \n",
      "Tickets, a creative tapas bar, has earned a 5 star rating.                                                 \n",
      "Maido, specializing in Nikkei cuisine, holds 1 stars.                                                      \n",
      "Odette, a French fine dining restaurant, has received 4 stars.                                             \n",
      "White Rabbit, serving modern Russian cuisine, maintains a 2 star rating.                                   \n",
      "Ultraviolet, an avant-garde dining experience, has been awarded 6 stars.                                   \n",
      "Arpège, known for its vegetable-focused French cuisine, holds 5 stars.                                     \n",
      "Mugaritz, an experimental restaurant, has earned a 4 star rating.                                          \n",
      "L'Enclume, offering modern British fare, maintains 1 stars.                                                \n",
      "Azurmendi, a Basque culinary destination, has received 1 stars.                                            \n",
      "Piazza Duomo, an Italian fine dining establishment, holds a 3 star rating.                                 \n",
      "The Ledbury, serving modern European cuisine, has been given 3 stars.                                      \n",
      "Amber, a French contemporary restaurant, boasts 7 stars.                                                   \n",
      "De Librije, showcasing Dutch cuisine, has earned a 2 star rating.                                          \n",
      "Astrid y Gastón, a Peruvian culinary landmark, holds 4 stars.                                              \n",
      "Nihonryori RyuGin, specializing in Japanese cuisine, has received 4 stars.                                 \n",
      "Restaurant Tim Raue, offering Asian-inspired dishes, maintains a 7 star rating.                            \n",
      "Vendôme, a modern German restaurant, has been awarded 6 stars.                                             \n",
      "Boragó, featuring Chilean ingredients, holds a 6 star rating.                                              \n",
      "Burnt Ends, a modern barbecue restaurant, has earned 7 stars.                                              \n",
      "Fäviken, a New Nordic culinary destination, maintains 6 stars.                                             \n",
      "Saison, serving contemporary American cuisine, has received a 3 star rating.                               \n",
      "Geranium, offering Scandinavian flavors, boasts 4 stars.                                                   \n",
      "Maaemo, a New Nordic fine dining establishment, holds 7 stars.                                             \n",
      "SingleThread, showcasing Californian produce, has been given 4 stars.                                      \n",
      "Enigma, an avant-garde dining experience, has earned a 1 star rating.                                      \n",
      "Leo, featuring Colombian biodiversity, maintains 3 stars.                                                  \n",
      "Core by Clare Smyth, a modern British restaurant, has received 5 stars.                                    \n",
      "Atelier Crenn, offering modern French cuisine, holds a 3 star rating.                                      \n",
      "Tickets, a creative tapas bar, has earned 7 stars.                                                         \n",
      "Aponiente, specializing in seafood, maintains a 5 star rating.                                             \n",
      "Schloss Schauenstein, a Swiss culinary castle, has been awarded 1 stars.                                   \n",
      "DiverXO, known for its fusion cuisine, holds 7 stars.                                                      \n",
      "The Test Kitchen, an eclectic dining experience, has received a 2 star rating.                             \n",
      "Lyle's, serving modern British fare, boasts 4 stars.                                                       \n",
      "Cosme, a contemporary Mexican restaurant, maintains 1 stars.                                               \n",
      "Relae, offering New Nordic cuisine, has earned a 4 star rating.                                            \n",
      "Alo, a contemporary French restaurant, holds 6 stars.                                                      \n",
      "Benu, featuring Asian-influenced American cuisine, has been given 2 stars.                                 \n",
      "Frantzen, offering Nordic-Asian fusion, has received a 2 star rating.                                      \n",
      "Tegui, an Argentine culinary gem, maintains 1 stars.                                                       \n",
      "The Clove Club, serving modern British cuisine, holds 2 stars.                                             \n",
      "Lido 84, an Italian lakeside restaurant, has earned a 5 star rating.                                       \n",
      "Hiša Franko, showcasing Slovenian flavors, boasts 2 stars.                                                 \n",
      "Elkano, a Basque grilled fish specialist, maintains 4 stars.                                               \n",
      "A Casa do Porco, celebrating Brazilian pork dishes, has received 4 stars.                                  \n",
      "Sühring, offering modern German cuisine, holds a 7 star rating.                                            \n",
      "Den, a playful Japanese restaurant, has been awarded 4 stars.                                              \n",
      "Twins Garden, serving modern Russian cuisine, maintains 7 stars.                                           \n",
      "The Jane, a modern European eatery, has earned a 4 star rating.                                            \n",
      "Nobelhart & Schmutzig, focusing on regional German ingredients, holds 5 stars.                             \n",
      "Mathias Dahlgren, a Nordic culinary destination, has received 7 stars.                                     \n",
      "Florilège, known for innovative French cuisine, boasts a 3 star rating.                                    \n",
      "Neolokal, offering modern Turkish dishes, maintains 6 stars.                                               \n",
      "Kadeau, a Nordic island-inspired restaurant, has earned 1 stars.                                           \n",
      "Mume, featuring Taiwan-inspired cuisine, holds a 4 star rating.                                            \n",
      "The Chairman, a Cantonese culinary gem, has been given 2 stars.                                            \n",
      "Tishe, showcasing modern Ukrainian cuisine, has received 4 stars.                                          \n",
      "108, a New Nordic casual dining spot, maintains a 2 star rating.                                           \n",
      "Ossiano, an underwater seafood restaurant, has earned 6 stars.                                             \n",
      "Blue Hill at Stone Barns, a pioneer in farm-to-table dining, has earned a 6 star rating.                   \n",
      "Disfrutar, known for avant-garde Mediterranean cuisine, holds 6 stars.                                     \n",
      "Virgilio Martínez, exploring Peruvian altitude ecosystems, has received 2 stars.                           \n",
      "Lasai, offering Brazilian-French fusion, maintains a 4 star rating.                                        \n",
      "Gaa, a modern Indian restaurant, has been awarded 6 stars.                                                 \n",
      "Atomix, serving Korean-inspired tasting menus, boasts 5 stars.                                             \n",
      "Sorn, specializing in Southern Thai cuisine, holds a 7 star rating.                                        \n",
      "La Colombe, known for French-Asian fusion, has earned 2 stars.                                             \n",
      "Lyle's, a modern British eatery, maintains 2 stars.                                                        \n",
      "Enigma, offering a conceptual dining experience, has received a 4 star rating.                             \n",
      "Septime, a neo-bistro in Paris, holds 2 stars.                                                             \n",
      "Tickets, known for creative tapas, has been given 2 stars.                                                 \n",
      "The Restaurant at Meadowood, showcasing California cuisine, boasts a 6 star rating.                        \n",
      "Toyo Eatery, celebrating modern Filipino flavors, has earned 4 stars.                                      \n",
      "Noma, a pioneer in New Nordic cuisine, maintains 6 stars.                                                  \n",
      "Akelarre, a Basque culinary institution, holds a 7 star rating.                                            \n",
      "Quince, blending Californian and Italian influences, has received 7 stars.                                 \n",
      "Ultraviolet by Paul Pairet, offering a multi-sensory experience, boasts 6 stars.                           \n"
     ]
    }
   ],
   "source": [
    "# peek into first test case \n",
    "\n",
    "print(test_cases[0][\"query\"][\"query\"])\n",
    "\n",
    "for case, rel in zip(test_cases[0][\"candidates\"][\"numeral\"], test_cases[0][\"relevance_scores\"]):\n",
    "    print(f\"{case:90} {'✔️' if rel == 1 else '':15} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'query': 'Show me restaurants rated above 7 stars',\n",
       "  'query_lex': 'Show me restaurants rated above seven stars'},\n",
       " 'candidates': {'numeral': ['Tickets, known for creative tapas, has been given 10 stars.',\n",
       "   'The Restaurant at Meadowood, showcasing California cuisine, boasts a 9 star rating.',\n",
       "   'Toyo Eatery, celebrating modern Filipino flavors, has earned 6 stars.',\n",
       "   'Septime, a neo-bistro in Paris, holds 5 stars.'],\n",
       "  'lexical': ['Tickets, known for creative tapas, has been given ten stars.',\n",
       "   'The Restaurant at Meadowood, showcasing California cuisine, boasts a nine star rating.',\n",
       "   'Toyo Eatery, celebrating modern Filipino flavors, has earned six stars.',\n",
       "   'Septime, a neo-bistro in Paris, holds five stars.']},\n",
       " 'relevance_scores': [1, 1, 0, 0]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try out test sample generation\n",
    "generate_test_sample(\n",
    "    query=\"Show me restaurants rated above {} stars\", \n",
    "    operator=\">\",\n",
    "    candidates=[\n",
    "        \"Tickets, known for creative tapas, has been given {} stars.\",\n",
    "        \"The Restaurant at Meadowood, showcasing California cuisine, boasts a {} star rating.\",\n",
    "        \"Toyo Eatery, celebrating modern Filipino flavors, has earned {} stars.\",\n",
    "        \"Septime, a neo-bistro in Paris, holds {} stars.\",\n",
    "    ], \n",
    "    max_items_to_retrieve=3, \n",
    "    target_number=7,\n",
    "    random_seed=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_samples_for_query(\n",
    "    query_item: Tuple[str, str],\n",
    "    candidates: List[str],\n",
    "    max_items_to_retrieve: int, \n",
    "    random_seeds: List[int]) -> Generator:\n",
    "    \"\"\"\n",
    "    Generate a test dataset for the item retrieval task.\n",
    "    \"\"\"\n",
    "    # unpack the query item\n",
    "    query, operator = query_item\n",
    "\n",
    "    # generate test samples for each target number\n",
    "    # sample a target number \n",
    "    for rand_seed in random_seeds:\n",
    "        np.random.seed(rand_seed)\n",
    "\n",
    "        target_number = np.random.randint(6, 10)\n",
    "\n",
    "        yield generate_test_sample(\n",
    "            query=query, \n",
    "            operator=operator,\n",
    "            candidates=candidates,\n",
    "            max_items_to_retrieve=max_items_to_retrieve,\n",
    "            target_number=target_number,\n",
    "            random_seed=rand_seed\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = []\n",
    "\n",
    "for q in restaurant_queries:\n",
    "    test_cases.extend(\n",
    "        [\n",
    "            t_case for t_case in generate_test_samples_for_query(\n",
    "                query_item=q,\n",
    "                candidates=restaurant_documents,\n",
    "                max_items_to_retrieve=10,\n",
    "                random_seeds=[\n",
    "                    42, 1234, 5678, 9101, 321, 765, 13, 1212, 42, 8, 46648\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_to_emoji = {0: \"\", 1: \"✅\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the performance of the model\n",
    "# code to evaluate a single test case and return precision and recall at 10\n",
    "def evaluate_test_case(\n",
    "        query: str, \n",
    "        candidates: List[str], \n",
    "        relevance_scores: List[int],\n",
    "        top_k: int, \n",
    "        model: SentenceTransformer,\n",
    "        debug=False) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a test case using a given model.\n",
    "    :param query: a query sentence\n",
    "    :param candidates: a list of candidate sentences\n",
    "    :param relevance_score: a list of relevance scores\n",
    "    :param top_k: the number of items to retrieve\n",
    "    :param model: a sentence transformer model to use\n",
    "    :return: a tuple of precision and recall at 10\n",
    "    \"\"\"\n",
    "    # encode the query and candidates\n",
    "    query_embedding = model.encode(query) #.reshape(1, -1)\n",
    "    candidate_embeddings = model.encode(candidates)\n",
    "\n",
    "    # compute the cosine similarity between the query and candidates\n",
    "    similarity = np.dot(candidate_embeddings, query_embedding.T)\n",
    "\n",
    "    # rank the candidates based on the similarity\n",
    "    ranked_indices = np.argsort(similarity, axis=0)[::-1]\n",
    "\n",
    "    ranked_similarity = similarity[ranked_indices]\n",
    "\n",
    "    # retrieve the relevance scores based on the ranking\n",
    "    ranked_relevance = np.array(relevance_scores)[ranked_indices]\n",
    "\n",
    "    # print query and top 10 results\n",
    "    if debug:\n",
    "        print(f\"Query: {query}\")\n",
    "        print()\n",
    "        print(\"\\n\".join(\n",
    "            [\n",
    "                f\"{i + 1:>3}: {candidates[j]:<90}{ranked_similarity[i]:>5.3f} {hit_to_emoji[ranked_relevance[i]]:>3}\" \\\n",
    "                    for i, j in enumerate(ranked_indices[:top_k])\n",
    "            ]), end=''\n",
    "        ) \n",
    "        print() \n",
    "\n",
    "    # compute precision and recall at 10\n",
    "    precision_at_k = np.sum(ranked_relevance[:top_k]) / top_k\n",
    "    recall_at_k = np.sum(ranked_relevance[:top_k]) / np.sum(relevance_scores)\n",
    "\n",
    "    return precision_at_k, recall_at_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the performance of the model\n",
    "# code to evaluate a single test case and return precision and recall at 10\n",
    "def evaluate_test_case_faiss(\n",
    "        query: str, \n",
    "        candidates: List[str], \n",
    "        relevance_scores: List[int],\n",
    "        top_k: int, \n",
    "        model: SentenceTransformer,\n",
    "        debug=False) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a test case using a given model.\n",
    "    :param query: a query sentence\n",
    "    :param candidates: a list of candidate sentences\n",
    "    :param relevance_score: a list of relevance scores\n",
    "    :param top_k: the number of items to retrieve\n",
    "    :param model: a sentence transformer model to use\n",
    "    :return: a tuple of precision and recall at 10\n",
    "    \"\"\"\n",
    "    # encode the query and candidates\n",
    "    query_embedding = model.encode(query).reshape(1, -1)\n",
    "    candidate_embeddings = model.encode(candidates)\n",
    "\n",
    "    # use faiss to normalize the vectors\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    faiss.normalize_L2(candidate_embeddings)\n",
    "\n",
    "    # compute the cosine similarity between the query and candidates using faiss\n",
    "    index = faiss.IndexFlatIP(candidate_embeddings.shape[1])\n",
    "    index.add(candidate_embeddings)\n",
    "    ranked_similarity, ranked_indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    # retrieve the relevance scores based on the ranking\n",
    "    relevance_scores = np.array(relevance_scores)\n",
    "    ranked_relevance = relevance_scores[ranked_indices[0]]\n",
    "\n",
    "    # print query and top 10 results\n",
    "    if debug:\n",
    "        print(f\"Query: {query}\")\n",
    "        print()\n",
    "        print(\"\\n\".join(\n",
    "            [\n",
    "                f\"{i + 1:>3}: {candidates[j]:<90}{ranked_similarity[0][i]:>5.3f} {hit_to_emoji[ranked_relevance[i]]:>3}\" \\\n",
    "                    for i, j in enumerate(ranked_indices[0][:top_k])\n",
    "            ]), end=''\n",
    "        ) \n",
    "        print() \n",
    "\n",
    "    # compute precision and recall at 10\n",
    "    precision_at_k = np.sum(ranked_relevance[:top_k]) / top_k\n",
    "    recall_at_k = np.sum(ranked_relevance[:top_k]) / np.sum(relevance_scores)\n",
    "\n",
    "    return precision_at_k, recall_at_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 μs, sys: 0 ns, total: 2 μs\n",
      "Wall time: 3.81 μs\n",
      "Query: Show me restaurants rated above 8 stars\n",
      "\n",
      "  1: The Restaurant at Meadowood, showcasing California cuisine, boasts a 7 star rating.       0.663    \n",
      "  2: Toyo Eatery, celebrating modern Filipino flavors, has earned 8 stars.                     0.486    \n",
      "  3: Tickets, known for creative tapas, has been given 9 stars.                                0.440   ✅\n",
      "  4: Septime, a neo-bistro in Paris, holds 8 stars.                                            0.376    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "evaluate_test_case(\n",
    "    query=\"Show me restaurants rated above 8 stars\",\n",
    "    candidates=[\n",
    "        \"Tickets, known for creative tapas, has been given 9 stars.\",\n",
    "        \"The Restaurant at Meadowood, showcasing California cuisine, boasts a 7 star rating.\",\n",
    "        \"Toyo Eatery, celebrating modern Filipino flavors, has earned 8 stars.\",\n",
    "        \"Septime, a neo-bistro in Paris, holds 8 stars.\",\n",
    "    ],\n",
    "    relevance_scores=[1, 0, 0, 0],\n",
    "    top_k=4,\n",
    "    model=encoder_models[\"miniLM-L6\"],\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 μs, sys: 0 ns, total: 1 μs\n",
      "Wall time: 2.86 μs\n",
      "Query: I have more than 7 apples.\n",
      "\n",
      "  1: I have 8 apples.                                                                          0.926    \n",
      "  2: I have 6 apples.                                                                          0.923    \n",
      "  3: I have 9 apples.                                                                          0.918    \n",
      "  4: I have 5 apples.                                                                          0.916    \n",
      "  5: I have 12 apples.                                                                         0.910    \n",
      "  6: I have 10 apples.                                                                         0.897    \n",
      "  7: I have 4 apples.                                                                          0.881    \n",
      "  8: I have 3 apples.                                                                          0.880    \n",
      "  9: I have 2 apples.                                                                          0.843   ✅\n",
      " 10: I have 11 apple.                                                                          0.746    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1, 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "evaluate_test_case(\n",
    "    query=\"I have more than 7 apples.\",\n",
    "    candidates=[\n",
    "        \"I have 2 apples.\",\n",
    "        \"I have 3 apples.\",\n",
    "        \"I have 4 apples.\",\n",
    "        \"I have 5 apples.\",\n",
    "        \"I have 6 apples.\",\n",
    "        \"I have 8 apples.\",\n",
    "        \"I have 9 apples.\",\n",
    "        \"I have 10 apples.\",\n",
    "        \"I have 11 apple.\",\n",
    "        \"I have 12 apples.\",\n",
    "    ],\n",
    "    relevance_scores=[1, 0, 0, 0, 0, 0, 0, 0, 0, 0,],\n",
    "    top_k=10,\n",
    "    model=encoder_models[\"miniLM-L6\"],\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 μs, sys: 0 ns, total: 2 μs\n",
      "Wall time: 4.77 μs\n",
      "Query: Show me restaurants rated above 8 stars\n",
      "\n",
      "  1: Toyo Eatery, celebrating modern Filipino flavors, has earned 8 stars.                     0.442    \n",
      "  2: The Restaurant at Meadowood, showcasing California cuisine, boasts a 7 star rating.       0.413    \n",
      "  3: Tickets, known for creative tapas, has been given 9 stars.                                0.372   ✅\n",
      "  4: Septime, a neo-bistro in Paris, holds 8 stars.                                            0.354    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 1.0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "evaluate_test_case_faiss(\n",
    "    query=\"Show me restaurants rated above 8 stars\",\n",
    "    candidates=[\n",
    "        \"Tickets, known for creative tapas, has been given 9 stars.\",\n",
    "        \"The Restaurant at Meadowood, showcasing California cuisine, boasts a 7 star rating.\",\n",
    "        \"Toyo Eatery, celebrating modern Filipino flavors, has earned 8 stars.\",\n",
    "        \"Septime, a neo-bistro in Paris, holds 8 stars.\",\n",
    "    ],\n",
    "    relevance_scores=[1, 0, 0, 0],\n",
    "    top_k=4,\n",
    "    model=encoder_models[\"LaBSE\"],\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 μs, sys: 0 ns, total: 2 μs\n",
      "Wall time: 3.81 μs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1e978f9a6d4f9fbcbdf351e26bdb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Show me restaurants rated above 8 stars\n",
      "\n",
      "  1: The Test Kitchen, an eclectic dining experience, has received a 8 star rating.            0.675    \n",
      "  2: The Restaurant at Meadowood, showcasing California cuisine, boasts a 6 star rating.       0.647    \n",
      "  3: Mugaritz, an experimental restaurant, has earned a 5 star rating.                         0.639    \n",
      "  4: Eleven Madison Park, serving contemporary American cuisine, is rated 3 stars.             0.633    \n",
      "  5: Joe's Place, a classic American diner, received a 9 star rating from customers.           0.598   ✅\n",
      "  6: Gaa, a modern Indian restaurant, has been awarded 1 stars.                                0.591    \n",
      "  7: Core by Clare Smyth, a modern British restaurant, has received 7 stars.                   0.578    \n",
      "  8: Le Bernardin, a seafood restaurant, has a 10 star rating.                                 0.575   ✅\n",
      "  9: Alo, a contemporary French restaurant, holds 3 stars.                                     0.568    \n",
      " 10: Lido 84, an Italian lakeside restaurant, has earned a 2 star rating.                      0.567    \n",
      "\n",
      "Query: Show me restaurants rated above 9 stars\n",
      "\n",
      "  1: The Restaurant at Meadowood, showcasing California cuisine, boasts a 7 star rating.       0.653    \n",
      "  2: Eleven Madison Park, serving contemporary American cuisine, is rated 1 stars.             0.651    \n",
      "  3: The Test Kitchen, an eclectic dining experience, has received a 5 star rating.            0.635    \n",
      "  4: Saison, serving contemporary American cuisine, has received a 9 star rating.              0.611    \n",
      "  5: Mugaritz, an experimental restaurant, has earned a 4 star rating.                         0.607    \n",
      "  6: Joe's Place, a classic American diner, received a 10 star rating from customers.          0.588   ✅\n",
      "  7: Alo, a contemporary French restaurant, holds 5 stars.                                     0.587    \n",
      "  8: Le Bernardin, a seafood restaurant, has a 10 star rating.                                 0.582   ✅\n",
      "  9: Vendôme, a modern German restaurant, has been awarded 6 stars.                            0.568    \n",
      " 10: Lido 84, an Italian lakeside restaurant, has earned a 8 star rating.                      0.567    \n",
      "\n",
      "Query: Show me restaurants rated above 6 stars\n",
      "\n",
      "  1: Eleven Madison Park, serving contemporary American cuisine, is rated 6 stars.             0.660    \n",
      "  2: The Test Kitchen, an eclectic dining experience, has received a 3 star rating.            0.640    \n",
      "  3: The Restaurant at Meadowood, showcasing California cuisine, boasts a 1 star rating.       0.637    \n",
      "  4: Mugaritz, an experimental restaurant, has earned a 3 star rating.                         0.622    \n",
      "  5: Joe's Place, a classic American diner, received a 9 star rating from customers.           0.595   ✅\n",
      "  6: Core by Clare Smyth, a modern British restaurant, has received 5 stars.                   0.592    \n",
      "  7: Saison, serving contemporary American cuisine, has received a 5 star rating.              0.589    \n",
      "  8: Vendôme, a modern German restaurant, has been awarded 6 stars.                            0.587    \n",
      "  9: Restaurant Tim Raue, offering Asian-inspired dishes, maintains a 5 star rating.           0.577    \n",
      " 10: Lido 84, an Italian lakeside restaurant, has earned a 5 star rating.                      0.576    \n",
      "\n",
      "Query: Show me restaurants rated above 7 stars\n",
      "\n",
      "  1: The Restaurant at Meadowood, showcasing California cuisine, boasts a 7 star rating.       0.677    \n",
      "  2: Gaa, a modern Indian restaurant, has been awarded 7 stars.                                0.651    \n",
      "  3: Eleven Madison Park, serving contemporary American cuisine, is rated 4 stars.             0.637    \n",
      "  4: The Test Kitchen, an eclectic dining experience, has received a 3 star rating.            0.623    \n",
      "  5: Mugaritz, an experimental restaurant, has earned a 4 star rating.                         0.608    \n",
      "  6: Saison, serving contemporary American cuisine, has received a 7 star rating.              0.606    \n",
      "  7: Alo, a contemporary French restaurant, holds 7 stars.                                     0.604    \n",
      "  8: Le Bernardin, a seafood restaurant, has a 9 star rating.                                  0.600   ✅\n",
      "  9: Den, a playful Japanese restaurant, has been awarded 7 stars.                             0.586    \n",
      " 10: Joe's Place, a classic American diner, received a 10 star rating from customers.          0.585   ✅\n",
      "\n",
      "Query: Show me restaurants rated above 6 stars\n",
      "\n",
      "  1: Mugaritz, an experimental restaurant, has earned a 5 star rating.                         0.640    \n",
      "  2: The Test Kitchen, an eclectic dining experience, has received a 3 star rating.            0.640    \n",
      "  3: Eleven Madison Park, serving contemporary American cuisine, is rated 4 stars.             0.635    \n",
      "  4: The Restaurant at Meadowood, showcasing California cuisine, boasts a 3 star rating.       0.631    \n",
      "  5: Core by Clare Smyth, a modern British restaurant, has received 5 stars.                   0.592    \n",
      "  6: Joe's Place, a classic American diner, received a 10 star rating from customers.          0.586   ✅\n",
      "  7: Vendôme, a modern German restaurant, has been awarded 5 stars.                            0.585    \n",
      "  8: Le Bernardin, a seafood restaurant, has a 9 star rating.                                  0.582   ✅\n",
      "  9: Gaa, a modern Indian restaurant, has been awarded 2 stars.                                0.573    \n",
      " 10: Saison, serving contemporary American cuisine, has received a 3 star rating.              0.564    \n",
      "\n",
      "Query: Show me restaurants rated above 7 stars\n",
      "\n",
      "  1: The Test Kitchen, an eclectic dining experience, has received a 5 star rating.            0.648    \n",
      "  2: The Restaurant at Meadowood, showcasing California cuisine, boasts a 1 star rating.       0.627    \n",
      "  3: Eleven Madison Park, serving contemporary American cuisine, is rated 3 stars.             0.627    \n",
      "  4: Gaa, a modern Indian restaurant, has been awarded 6 stars.                                0.623    \n",
      "  5: Alo, a contemporary French restaurant, holds 5 stars.                                     0.601    \n",
      "  6: Le Bernardin, a seafood restaurant, has a 10 star rating.                                 0.591   ✅\n",
      "  7: Core by Clare Smyth, a modern British restaurant, has received 5 stars.                   0.590    \n",
      "  8: Mugaritz, an experimental restaurant, has earned a 2 star rating.                         0.590    \n",
      "  9: Joe's Place, a classic American diner, received a 10 star rating from customers.          0.585   ✅\n",
      " 10: Vendôme, a modern German restaurant, has been awarded 5 stars.                            0.583    \n",
      "\n",
      "Query: Show me restaurants rated above 8 stars\n",
      "\n",
      "  1: Eleven Madison Park, serving contemporary American cuisine, is rated 7 stars.             0.661    \n",
      "  2: Mugaritz, an experimental restaurant, has earned a 6 star rating.                         0.642    \n",
      "  3: The Test Kitchen, an eclectic dining experience, has received a 6 star rating.            0.641    \n",
      "  4: The Restaurant at Meadowood, showcasing California cuisine, boasts a 4 star rating.       0.628    \n",
      "  5: Saison, serving contemporary American cuisine, has received a 8 star rating.              0.603    \n",
      "  6: Joe's Place, a classic American diner, received a 9 star rating from customers.           0.598   ✅\n",
      "  7: Le Bernardin, a seafood restaurant, has a 9 star rating.                                  0.587   ✅\n",
      "  8: Lido 84, an Italian lakeside restaurant, has earned a 4 star rating.                      0.573    \n",
      "  9: Vendôme, a modern German restaurant, has been awarded 7 stars.                            0.573    \n",
      " 10: Alo, a contemporary French restaurant, holds 3 stars.                                     0.568    \n",
      "\n",
      "Query: Show me restaurants rated above 6 stars\n",
      "\n",
      "  1: The Restaurant at Meadowood, showcasing California cuisine, boasts a 6 star rating.       0.669    \n",
      "  2: The Test Kitchen, an eclectic dining experience, has received a 5 star rating.            0.657    \n",
      "  3: Eleven Madison Park, serving contemporary American cuisine, is rated 1 stars.             0.627    \n",
      "  4: Alo, a contemporary French restaurant, holds 5 stars.                                     0.612    \n",
      "  5: Core by Clare Smyth, a modern British restaurant, has received 6 stars.                   0.603    \n",
      "  6: Joe's Place, a classic American diner, received a 9 star rating from customers.           0.595   ✅\n",
      "  7: Mugaritz, an experimental restaurant, has earned a 2 star rating.                         0.592    \n",
      "  8: Vendôme, a modern German restaurant, has been awarded 5 stars.                            0.585    \n",
      "  9: Den, a playful Japanese restaurant, has been awarded 6 stars.                             0.582    \n",
      " 10: Le Bernardin, a seafood restaurant, has a 9 star rating.                                  0.582   ✅\n",
      "\n",
      "Query: Show me restaurants rated above 8 stars\n",
      "\n",
      "  1: The Test Kitchen, an eclectic dining experience, has received a 8 star rating.            0.675    \n",
      "  2: The Restaurant at Meadowood, showcasing California cuisine, boasts a 6 star rating.       0.647    \n",
      "  3: Mugaritz, an experimental restaurant, has earned a 5 star rating.                         0.639    \n",
      "  4: Eleven Madison Park, serving contemporary American cuisine, is rated 3 stars.             0.633    \n",
      "  5: Joe's Place, a classic American diner, received a 9 star rating from customers.           0.598   ✅\n",
      "  6: Gaa, a modern Indian restaurant, has been awarded 1 stars.                                0.591    \n",
      "  7: Core by Clare Smyth, a modern British restaurant, has received 7 stars.                   0.578    \n",
      "  8: Le Bernardin, a seafood restaurant, has a 10 star rating.                                 0.575   ✅\n",
      "  9: Alo, a contemporary French restaurant, holds 3 stars.                                     0.568    \n",
      " 10: Lido 84, an Italian lakeside restaurant, has earned a 2 star rating.                      0.567    \n",
      "\n",
      "Query: Show me restaurants rated above 9 stars\n",
      "\n",
      "  1: Mugaritz, an experimental restaurant, has earned a 6 star rating.                         0.634    \n",
      "  2: Eleven Madison Park, serving contemporary American cuisine, is rated 2 stars.             0.629    \n",
      "  3: The Restaurant at Meadowood, showcasing California cuisine, boasts a 1 star rating.       0.628    \n",
      "  4: The Test Kitchen, an eclectic dining experience, has received a 1 star rating.            0.619    \n",
      "  5: Saison, serving contemporary American cuisine, has received a 7 star rating.              0.592    \n",
      "  6: Gaa, a modern Indian restaurant, has been awarded 4 stars.                                0.588    \n",
      "  7: Joe's Place, a classic American diner, received a 10 star rating from customers.          0.588   ✅\n",
      "  8: Alo, a contemporary French restaurant, holds 5 stars.                                     0.587    \n",
      "  9: Le Bernardin, a seafood restaurant, has a 10 star rating.                                 0.582   ✅\n",
      " 10: Restaurant Tim Raue, offering Asian-inspired dishes, maintains a 7 star rating.           0.579    \n",
      "\n",
      "Mean Recall@10: 0.379\n",
      "Std Recall@10: 0.137\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "recall_values = []\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    p, r = evaluate_test_case(\n",
    "        test_cases[i][\"query\"][\"numeral\"],\n",
    "        test_cases[i][\"candidates\"][\"numeral\"],\n",
    "        test_cases[i][\"relevance_scores\"],\n",
    "        top_k=10,\n",
    "        model=encoder_models[\"miniLM-L6\"],\n",
    "        debug=True\n",
    "    )\n",
    "    #print(f\"Case {i:>3}:    Recall@10: {r:.3f}\")\n",
    "    print()\n",
    "\n",
    "    recall_values.append(r)\n",
    "\n",
    "\n",
    "print(f\"Mean Recall@10: {np.mean(recall_values):.3f}\")\n",
    "print(f\"Std Recall@10: {np.std(recall_values):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: miniLM-L6    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8c183fe42e43d5a5881ee37c62509b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_cases))):\n\u001b[0;32m----> 7\u001b[0m     p, r \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_test_case\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumeral\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcandidates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumeral\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelevance_scores\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#print(f\"Case {i:>3}:    Recall@10: {r:.3f}\")\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#print()\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     recall_values\u001b[38;5;241m.\u001b[39mappend(r)\n",
      "Cell \u001b[0;32mIn[25], line 21\u001b[0m, in \u001b[0;36mevaluate_test_case\u001b[0;34m(query, candidates, relevance_scores, top_k, model, debug)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# encode the query and candidates\u001b[39;00m\n\u001b[1;32m     20\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(query) \u001b[38;5;66;03m#.reshape(1, -1)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m candidate_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# compute the cosine similarity between the query and candidates\u001b[39;00m\n\u001b[1;32m     24\u001b[0m similarity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(candidate_embeddings, query_embedding\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:517\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    514\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 517\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    519\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:118\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    116\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    121\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:626\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    623\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    624\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 626\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/pytorch_utils.py:238\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    638\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 551\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    553\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recall_values = []\n",
    "\n",
    "for encoder in encoder_models:\n",
    "\n",
    "    print(f\"Model: {encoder}    \", end=\"\")\n",
    "    for i in tqdm(range(len(test_cases))):\n",
    "        p, r = evaluate_test_case(\n",
    "            test_cases[i][\"query\"][\"numeral\"],\n",
    "            test_cases[i][\"candidates\"][\"numeral\"],\n",
    "            test_cases[i][\"relevance_scores\"],\n",
    "            top_k=10,\n",
    "            model=encoder_models[m]\n",
    "        )\n",
    "        #print(f\"Case {i:>3}:    Recall@10: {r:.3f}\")\n",
    "        #print()\n",
    "\n",
    "        recall_values.append(r)\n",
    "\n",
    "    print(f\"Mean Recall@10: {np.mean(recall_values):.3f}\")\n",
    "    print(f\"Std Recall@10: {np.std(recall_values):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75e6b7319034fa883b6090b2bb300ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Recall@10: 0.347\n",
      "Std Recall@10: 0.160\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(range(len(test_cases))):\n",
    "    p, r = evaluate_test_case(\n",
    "        test_cases[i][\"query\"][\"lexical\"],\n",
    "        test_cases[i][\"candidates\"][\"lexical\"],\n",
    "        test_cases[i][\"relevance_scores\"],\n",
    "        top_k=10,\n",
    "        model=encoder_models[\"miniLM-L6\"]\n",
    "    )\n",
    "    #print(f\"Case {i:>3}:    Recall@10: {r:.3f}\")\n",
    "    #print()\n",
    "\n",
    "    recall_values.append(r)\n",
    "\n",
    "\n",
    "print(f\"Mean R@10: {np.mean(recall_values):.3f}    \", end=\"\")\n",
    "print(f\" Std R@10: {np.std(recall_values):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " >>> generate_test_sample(\n",
    "    query=\"Show me restaurants rated above {} stars\"\", \n",
    "    candidates=[\n",
    "        \"Tickets, known for creative tapas, has been given {} stars.\"\n",
    "        \"The Restaurant at Meadowood, showcasing California cuisine, boasts a {} star rating.\"\n",
    "        \"Toyo Eatery, celebrating modern Filipino flavors, has earned {} stars.\"\n",
    "        \"Septime, a neo-bistro in Paris, holds {} stars.\"\n",
    "    ], \n",
    "    max_items_to_retrieve=2, \n",
    "    target_number=7\n",
    ")\n",
    "\n",
    "{\n",
    "    \"query\": \"Show me restaurants rated above 7 stars\",\n",
    "    \"comparison\": \">\",\n",
    "    \"candidates\": [\n",
    "        \"Tickets, known for creative tapas, has been given 6 stars.\",\n",
    "        \"The Restaurant at Meadowood, showcasing California cuisine, boasts a 8 star rating.\",\n",
    "        \"Toyo Eatery, celebrating modern Filipino flavors, has earned 5 stars.\", \n",
    "        \"Septime, a neo-bistro in Paris, holds 9 stars.\"\n",
    "    ],\n",
    "    \"relevance_scores\": [0, 1, 0, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the file resturants.list \n",
    "# and convert to list\n",
    "data = pd.read_csv(\"restaurants.list\", sep=\"\\t\", header=None).to_dict()[0]\n",
    "RESTAURANTS = list(data.values())\n",
    "\n",
    "data = pd.read_csv(\"movies.list\", sep=\"\\t\", header=None).to_dict()[0]\n",
    "MOVIES = list(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"restaurants\": {\n",
    "        \"query\": [\n",
    "            \"Find restaurants that are rated with at least {} {}\", \n",
    "            \"List all restaurants with {} {} rating or higher\",\n",
    "            \"I am looking for restaurants with at least {} {} rating\",\n",
    "            \"Show me restaurants that have {} {} rating or higher\",\n",
    "            \"Which restaurants have at least {} {} rating\",\n",
    "            \"Restaurants with at least {} {} rating\",\n",
    "            \"List restaurants with at least {} {} rating\",\n",
    "            \"Restaurants that have {} {} rating or higher\",\n",
    "            \"I want to see great restaurants with at least {} {} rating\",\n",
    "            \"Give me suggestions for restaurants with {} {} rating or higher\",\n",
    "            \"I want to know which restaurants have at least {} {} rating\",\n",
    "            \"Which restaurants have {} {} rating or higher\",\n",
    "            \"Great restaurants that have at least {} {} rating\",\n",
    "            \"Show me of restaurants with at least {} {} rating\",\n",
    "        ], \n",
    "        \"candidate\": \"{} restaurant has {} stars rating.\",\n",
    "        \"attribute\": \"stars\"\n",
    "    }, \n",
    "    \"movies\": {\n",
    "        \"query\": [\n",
    "            \"Find movies that are rated with at least {} {}\", \n",
    "            \"List all movies with {} {} rating or higher\",\n",
    "            \"I am looking for movies with at least {} {} rating\",\n",
    "            \"Show me movies that have {} {} rating or higher\",\n",
    "            \"Which movies have at least {} {} rating\",\n",
    "            \"Movies with at least {} {} rating\",\n",
    "            \"List movies with at least {} {} rating\",\n",
    "            \"Movies that have {} {} rating or higher\",\n",
    "            \"I want to see great movies with at least {} {} rating\",\n",
    "            \"Give me suggestions for movies with {} {} rating or higher\",\n",
    "            \"I want to know which movies have at least {} {} rating\",\n",
    "            \"Which movies have {} {} rating or higher\",\n",
    "            \"Great movies that have at least {} {} rating\",\n",
    "            \"Show me of movies with at least {} {} rating\",\n",
    "        ],\n",
    "        \"candidate\": \"The {} movie is rated with {} {}.\",\n",
    "        \"attribute\": \"stars\"\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_case(\n",
    "        attribute: str,\n",
    "        search_items: List[str],\n",
    "        query_template: str, \n",
    "        candidate_template: str, \n",
    "        max_items_to_retrieve: int=11) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a test case for the evaluation.\n",
    "    :param attribute: the attribute to be queried (e.g., \"stars\", \"awards\")\n",
    "    :param search_items: a list of items to search over (e.g., restaurants)\n",
    "    :param query_template: a query template to be used\n",
    "    :param candidate_template: a candidate template to be used\n",
    "    :return: a tuple of query sentence, candidate sentences, and hit flags\n",
    "    \"\"\"\n",
    "    # test if input parameters are valid\n",
    "    assert attribute in [\"stars\", \"awards\"], \"Invalid attribute\"\n",
    "    assert len(search_items) >= 1, \"Provide at least one search items\"\n",
    "\n",
    "    # sample a target number \n",
    "    target_number = np.random.randint(6, 10)\n",
    "\n",
    "    # associate a value for each search item\n",
    "    # where only N of those are equal to or higher than the target number\n",
    "    items_to_retrieve = np.random.randint(1, max_items_to_retrieve)\n",
    "\n",
    "    hit_ratings = np.random.randint(target_number, 10, items_to_retrieve)\n",
    "    miss_ratings = np.random.randint(\n",
    "        1, target_number, len(search_items) - items_to_retrieve\n",
    "    )\n",
    "    \n",
    "    item_ratings = np.concatenate([hit_ratings, miss_ratings])\n",
    "\n",
    "    # define a boolean list to check if the rating is hit (should be returned)\n",
    "    relevance_scores = [\n",
    "        0 if rating < target_number else 1 for rating in item_ratings\n",
    "    ]\n",
    "\n",
    "    # create the query sentence\n",
    "    query_sentence = query_template.format(target_number, attribute)\n",
    "    target_number_lex = number_lexicalizer.number_to_words(target_number)\n",
    "    query_sentence_lex = query_template.format(target_number_lex, attribute)\n",
    "\n",
    "    candidates = [\n",
    "        candidate_template.format(restaurant, rating)\n",
    "        for restaurant, rating in zip(search_items, item_ratings)\n",
    "    ]\n",
    "\n",
    "    candidates_lex = [\n",
    "        candidate_template.format(\n",
    "            restaurant, \n",
    "            number_lexicalizer.number_to_words(rating))\n",
    "        for restaurant, rating in zip(search_items, item_ratings)\n",
    "    ]\n",
    "\n",
    "\n",
    "    return { \n",
    "        \"query\": {\n",
    "            \"numeral\": query_sentence,\n",
    "            \"lexical\": query_sentence_lex\n",
    "        }, \n",
    "        \"candidates\": {\n",
    "            \"numeral\": candidates,\n",
    "            \"lexical\": candidates_lex\n",
    "        },\n",
    "        \"relevance_scores\": relevance_scores\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'numeral': 'Find restaurants that are rated with at least 6 stars',\n",
       "  'lexical': 'Find restaurants that are rated with at least six stars'},\n",
       " 'candidates': {'numeral': ['Taj Mahal restaurant has 9 stars rating.',\n",
       "   'Burger King restaurant has 4 stars rating.',\n",
       "   \"McDonald's restaurant has 1 stars rating.\",\n",
       "   'KFC restaurant has 5 stars rating.',\n",
       "   'Pizza Hut restaurant has 3 stars rating.',\n",
       "   'Subway restaurant has 4 stars rating.',\n",
       "   'Greggs restaurant has 3 stars rating.',\n",
       "   'Pret A Manger restaurant has 2 stars rating.',\n",
       "   \"Nando's restaurant has 1 stars rating.\",\n",
       "   'Starbucks restaurant has 1 stars rating.',\n",
       "   'Costa restaurant has 3 stars rating.'],\n",
       "  'lexical': ['Taj Mahal restaurant has nine stars rating.',\n",
       "   'Burger King restaurant has four stars rating.',\n",
       "   \"McDonald's restaurant has one stars rating.\",\n",
       "   'KFC restaurant has five stars rating.',\n",
       "   'Pizza Hut restaurant has three stars rating.',\n",
       "   'Subway restaurant has four stars rating.',\n",
       "   'Greggs restaurant has three stars rating.',\n",
       "   'Pret A Manger restaurant has two stars rating.',\n",
       "   \"Nando's restaurant has one stars rating.\",\n",
       "   'Starbucks restaurant has one stars rating.',\n",
       "   'Costa restaurant has three stars rating.']},\n",
       " 'relevance_scores': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = create_test_case(\n",
    "    \"stars\", \n",
    "    [\"Taj Mahal\", \"Burger King\", \"McDonald's\", \"KFC\", \"Pizza Hut\", \"Subway\", \n",
    "     \"Greggs\", \"Pret A Manger\", \"Nando's\", \"Starbucks\", \"Costa\"],\n",
    "    templates[\"restaurants\"][\"query\"][0],\n",
    "    templates[\"restaurants\"][\"candidate\"], \n",
    "    max_items_to_retrieve=5\n",
    ")\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate a single test case and return precision and recall at 10\n",
    "def evaluate_test_case(\n",
    "        query: str, \n",
    "        candidates: List[str], \n",
    "        relevance_scores: List[int], \n",
    "        model: SentenceTransformer) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a test case using a given model.\n",
    "    :param query: a query sentence\n",
    "    :param candidates: a list of candidate sentences\n",
    "    :param relevance_score: a list of relevance scores\n",
    "    :param model: a sentence transformer model to use\n",
    "    :return: a tuple of precision and recall at 10\n",
    "    \"\"\"\n",
    "    # encode the query and candidates\n",
    "    query_embedding = model.encode(query)\n",
    "    candidate_embeddings = model.encode(candidates)\n",
    "\n",
    "    # compute the cosine similarity between the query and candidates\n",
    "    similarity = np.dot(candidate_embeddings, query_embedding.T)\n",
    "\n",
    "    # rank the candidates based on the similarity\n",
    "    ranked_indices = np.argsort(similarity, axis=0)[::-1]\n",
    "\n",
    "    # retrieve the relevance scores based on the ranking\n",
    "    ranked_relevance = np.array(relevance_scores)[ranked_indices]\n",
    "\n",
    "    # compute precision and recall at 10\n",
    "    precision_at_10 = np.mean(ranked_relevance[:10])\n",
    "    recall_at_10 = np.sum(ranked_relevance[:10]) / np.sum(relevance_scores)\n",
    "\n",
    "    return precision_at_10, recall_at_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[\"relevance_scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 1.0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_test_case(\n",
    "    t[\"query\"][\"numeral\"], \n",
    "    t[\"candidates\"][\"numeral\"], \n",
    "    t[\"relevance_scores\"], \n",
    "    encoder_models[\"LaBSE\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_to_emoji = {0: \"✖\", 1: \"✅\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create test case 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Replacement index 2 out of range for positional args tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m search_need \u001b[38;5;129;01min\u001b[39;00m templates:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m query_template \u001b[38;5;129;01min\u001b[39;00m templates[search_need][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     22\u001b[0m         test_case_dict[search_need]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 23\u001b[0m             \u001b[43mcreate_test_case\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtemplates\u001b[49m\u001b[43m[\u001b[49m\u001b[43msearch_need\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattribute\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[43msearch_items\u001b[49m\u001b[43m[\u001b[49m\u001b[43msearch_need\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43mquery_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtemplates\u001b[49m\u001b[43m[\u001b[49m\u001b[43msearch_need\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcandidate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m         )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# evaluate the test cases\u001b[39;00m\n\u001b[1;32m     32\u001b[0m precision_at_10_values, recall_at_10_values \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[109], line 43\u001b[0m, in \u001b[0;36mcreate_test_case\u001b[0;34m(attribute, search_items, query_template, candidate_template, max_items_to_retrieve)\u001b[0m\n\u001b[1;32m     40\u001b[0m target_number_lex \u001b[38;5;241m=\u001b[39m number_lexicalizer\u001b[38;5;241m.\u001b[39mnumber_to_words(target_number)\n\u001b[1;32m     41\u001b[0m query_sentence_lex \u001b[38;5;241m=\u001b[39m query_template\u001b[38;5;241m.\u001b[39mformat(target_number_lex, attribute)\n\u001b[0;32m---> 43\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcandidate_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestaurant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrating\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrestaurant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrating\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msearch_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_ratings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     48\u001b[0m candidates_lex \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     49\u001b[0m     candidate_template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     50\u001b[0m         restaurant, \n\u001b[1;32m     51\u001b[0m         number_lexicalizer\u001b[38;5;241m.\u001b[39mnumber_to_words(rating))\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m restaurant, rating \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(search_items, item_ratings)\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m { \n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeral\u001b[39m\u001b[38;5;124m\"\u001b[39m: query_sentence,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelevance_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m: relevance_scores\n\u001b[1;32m     66\u001b[0m }\n",
      "Cell \u001b[0;32mIn[109], line 44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m target_number_lex \u001b[38;5;241m=\u001b[39m number_lexicalizer\u001b[38;5;241m.\u001b[39mnumber_to_words(target_number)\n\u001b[1;32m     41\u001b[0m query_sentence_lex \u001b[38;5;241m=\u001b[39m query_template\u001b[38;5;241m.\u001b[39mformat(target_number_lex, attribute)\n\u001b[1;32m     43\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mcandidate_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestaurant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrating\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m restaurant, rating \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(search_items, item_ratings)\n\u001b[1;32m     46\u001b[0m ]\n\u001b[1;32m     48\u001b[0m candidates_lex \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     49\u001b[0m     candidate_template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     50\u001b[0m         restaurant, \n\u001b[1;32m     51\u001b[0m         number_lexicalizer\u001b[38;5;241m.\u001b[39mnumber_to_words(rating))\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m restaurant, rating \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(search_items, item_ratings)\n\u001b[1;32m     53\u001b[0m ]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m { \n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeral\u001b[39m\u001b[38;5;124m\"\u001b[39m: query_sentence,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelevance_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m: relevance_scores\n\u001b[1;32m     66\u001b[0m }\n",
      "\u001b[0;31mIndexError\u001b[0m: Replacement index 2 out of range for positional args tuple"
     ]
    }
   ],
   "source": [
    "# iterate over the templates and create test cases\n",
    "search_items = {\n",
    "    \"restaurants\": RESTAURANTS, \n",
    "    \"movies\": MOVIES\n",
    "}\n",
    "\n",
    "\n",
    "debug = False\n",
    "\n",
    "model_name = \"LaBSE\"\n",
    "model = encoder_models[model_name]\n",
    "\n",
    "for k in range(10):\n",
    "    #print(f\"Experiment {k+1}\")\n",
    "    test_case_dict = defaultdict(list)\n",
    "\n",
    "    print(f'Create test case {k + 1}')\n",
    "\n",
    "    # generate test cases for each search need\n",
    "    for search_need in templates:\n",
    "        for query_template in templates[search_need][\"query\"]:\n",
    "            test_case_dict[search_need].append(\n",
    "                create_test_case(\n",
    "                    templates[search_need][\"attribute\"], \n",
    "                    search_items[search_need], \n",
    "                    query_template, \n",
    "                    templates[search_need][\"candidate\"], \n",
    "                )\n",
    "            )\n",
    "\n",
    "    # evaluate the test cases\n",
    "    precision_at_10_values, recall_at_10_values = [], []\n",
    "    for search_need in test_case_dict:\n",
    "\n",
    "        for t_case in test_case_dict[search_need]:\n",
    "            precision_at_10, recall_at_10 = evaluate_test_case(\n",
    "                t_case[\"query\"][\"numeral\"], \n",
    "                t_case[\"candidates\"][\"numeral\"], \n",
    "                t_case[\"relevance_scores\"], \n",
    "                model\n",
    "            )\n",
    "\n",
    "            precision_at_10_values.append(precision_at_10)\n",
    "            recall_at_10_values.append(recall_at_10)\n",
    "\n",
    "            if debug:\n",
    "                print(f\"Query: {t_case['query']['numeral']}\")\n",
    "                print()\n",
    "                for i, (candidate, relevance) in enumerate(\n",
    "                    zip(t_case[\"candidates\"][\"numeral\"], t_case[\"relevance_scores\"])\n",
    "                ):\n",
    "                    print(f\"Rank {i+1:>2}: {candidate:60} \", end=\"\")\n",
    "                    print(f\"{relevance_to_emoji[relevance]:>3}\")\n",
    "\n",
    "                print()\n",
    "                print(f\"P@10: {precision_at_10:.3f}\")\n",
    "                print(f\"R@10: {recall_at_10:.3f}\")\n",
    "                print()\n",
    "\n",
    "    avg_precision_at_10 = np.mean(precision_at_10_values)\n",
    "    avg_recall_at_10 = np.mean(recall_at_10_values)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Average P@10: {avg_precision_at_10:.3f}\")\n",
    "    print(f\"Average R@10: {avg_recall_at_10:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# URL of the webpage\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_cases[\"restaurants\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LaBSE\n",
      "Average P@10: 0.130\n",
      "Average R@10: 0.220\n",
      "--------------------------------------------------------------------------------\n",
      "Model: miniLM-L12\n",
      "Average P@10: 0.180\n",
      "Average R@10: 0.428\n",
      "--------------------------------------------------------------------------------\n",
      "Model: miniLM-L6\n",
      "Average P@10: 0.240\n",
      "Average R@10: 0.525\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# encode the query and the candidates\u001b[39;00m\n\u001b[1;32m     15\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(query)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m candidate_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# L2 normalize the embeddings\u001b[39;00m\n\u001b[1;32m     19\u001b[0m faiss\u001b[38;5;241m.\u001b[39mnormalize_L2(query_embedding)\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:517\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    514\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 517\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    519\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:118\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    116\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    121\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:626\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    623\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    624\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 626\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/pytorch_utils.py:238\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:638\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 638\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    538\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embeddings/lib/python3.11/site-packages/transformers/activations.py:78\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evalauting the models\n",
    "debug = False\n",
    "\n",
    "for model_name, model in encoder_models.items():\n",
    "\n",
    "    precision_at_10_values, recall_at_10_values = [], []\n",
    "\n",
    "    # iterate over the test cases\n",
    "    for t_case in test_cases[\"restaurants\"]:\n",
    "        # get the query and the candidates\n",
    "        query_sent, candidates = t_case[\"query\"], t_case[\"candidates\"]\n",
    "        relevance_scores = t_case[\"relevance_scores\"]\n",
    "\n",
    "        # encode the query and the candidates\n",
    "        query_embedding = model.encode(query_sent).reshape(1, -1)\n",
    "        candidate_embeddings = model.encode(candidates)\n",
    "\n",
    "        # L2 normalize the embeddings\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        faiss.normalize_L2(candidate_embeddings)\n",
    "\n",
    "        # get dimensions of the embeddings\n",
    "        d = query_embedding.shape[1]\n",
    "\n",
    "        # make search index\n",
    "        index = faiss.IndexFlatIP(d)\n",
    "        index.add(candidate_embeddings)\n",
    "\n",
    "        # search the index\n",
    "        k = 10\n",
    "\n",
    "        D, I = index.search(query_embedding, k)\n",
    "\n",
    "        if debug:\n",
    "\n",
    "            print(f\"Query: {query_sent}\")\n",
    "            print()\n",
    "\n",
    "            for i in range(k):\n",
    "                retrieved_sentence = candidates[I[0][i]]\n",
    "                hit_or_not = relevance_scores[I[0][i]]\n",
    "                print(f\"Rank {i+1:>2}: {retrieved_sentence:60} \", end=\"\")\n",
    "                print(f\"{D[0][i]:>5.4f} \", end=\"\")\n",
    "                print(f\"{relevance_to_emoji[hit_or_not]:>3}\")\n",
    "\n",
    "\n",
    "        # compute precision and recall at 10\n",
    "        retrieved_items = sum(np.array(relevance_scores)[I[0]])\n",
    "\n",
    "        precision_at_10 = retrieved_items / k\n",
    "        recall_at_10 = retrieved_items / np.sum(relevance_scores)\n",
    "\n",
    "        precision_at_10_values.append(precision_at_10)\n",
    "        recall_at_10_values.append(recall_at_10)\n",
    "\n",
    "        if debug:\n",
    "\n",
    "            print()\n",
    "            print(f\"Total num of relevant items: {np.sum(relevance_scores)}\")\n",
    "            print(f\"Total num of retrieved items: {retrieved_items}\")\n",
    "\n",
    "            print()\n",
    "            print(f\"P@10: {precision_at_10:.3f}\")\n",
    "            print(f\"R@10: {recall_at_10:.3f}\")\n",
    "            print()\n",
    "\n",
    "    # caluclate the average precision and recall at 10\n",
    "    avg_precision_at_10 = np.mean(precision_at_10_values)\n",
    "    avg_recall_at_10 = np.mean(recall_at_10_values)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Average P@10: {avg_precision_at_10:.3f}\")\n",
    "    print(f\"Average R@10: {avg_recall_at_10:.3f}\")\n",
    "\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Replacement index 1 out of range for positional args tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m target_number \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m query_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShow me restaurants with at least \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m rating\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m query_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mquery_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_number\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# create a list of randome ratings between 1 and 10\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# where only 10 of those are equal to or higher than the target number\u001b[39;00m\n\u001b[1;32m      8\u001b[0m hit_ratings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(target_number, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Replacement index 1 out of range for positional args tuple"
     ]
    }
   ],
   "source": [
    "# sample target number\n",
    "target_number = np.random.randint(6, 10)\n",
    "query_template = \"Show me restaurants with at least {} {} rating\"\n",
    "query_sentence = query_template.format(target_number)\n",
    "\n",
    "# create a list of randome ratings between 1 and 10\n",
    "# where only 10 of those are equal to or higher than the target number\n",
    "hit_ratings = np.random.randint(target_number, 11, 10)\n",
    "miss_ratings = np.random.randint(1, target_number, len(RESTAURANTS) - 10)\n",
    "all_ratings = np.concatenate([hit_ratings, miss_ratings])\n",
    "\n",
    "#ratings = np.random.randint(1, 11, len(RESTAURANTS))\n",
    "\n",
    "\n",
    "candidate_template = \"{} restaurant has {} stars rating.\"\n",
    "\n",
    "# define a boolean list to check if the rating is hit (should be returned)\n",
    "is_hit = [\n",
    "    0 if rating < target_number else 1 for rating in all_ratings\n",
    "]\n",
    "\n",
    "candidate_sentences = [\n",
    "        candidate_template.format(restaurant, rating)\n",
    "        for restaurant, rating in zip(RESTAURANTS, all_ratings)\n",
    "]\n",
    "\n",
    "hit_to_emoji = {0: \"✖\", 1: \"✅\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(is_hit) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holy Cannoli! restaurant has 8 stars rating.                      ✅\n",
      "Sushi Samurai restaurant has 7 stars rating.                      ✅\n",
      "Nacho Average Taco restaurant has 8 stars rating.                 ✅\n",
      "Curry Up Now restaurant has 8 stars rating.                       ✅\n",
      "Oui, Chef! restaurant has 10 stars rating.                        ✅\n",
      "The Souvlaki Shack restaurant has 10 stars rating.                ✅\n",
      "Kimchi Commandos restaurant has 9 stars rating.                   ✅\n",
      "Pad Thai Guy restaurant has 10 stars rating.                      ✅\n",
      "Tagine Time restaurant has 10 stars rating.                       ✅\n",
      "Carnivore Carnival restaurant has 9 stars rating.                 ✅\n",
      "Wok This Way restaurant has 4 stars rating.                       ✖\n",
      "Hummus a Tune restaurant has 5 stars rating.                      ✖\n",
      "Rumba Roti restaurant has 4 stars rating.                         ✖\n",
      "Lederhosen Lounge restaurant has 3 stars rating.                  ✖\n",
      "Mamma Mia's Pizzeria restaurant has 1 stars rating.               ✖\n",
      "Dim Sum Drummers restaurant has 1 stars rating.                   ✖\n",
      "New York Cheesecake Factory restaurant has 4 stars rating.        ✖\n",
      "Grillin' & Chillin' restaurant has 5 stars rating.                ✖\n",
      "Gyro Hero restaurant has 6 stars rating.                          ✖\n",
      "Persian Cat Café restaurant has 2 stars rating.                   ✖\n",
      "Gaucho Grillhouse restaurant has 2 stars rating.                  ✖\n",
      "Tuk Tuk Thai restaurant has 2 stars rating.                       ✖\n",
      "Pizza My Heart restaurant has 1 stars rating.                     ✖\n",
      "Pineapple Express restaurant has 1 stars rating.                  ✖\n",
      "Spice Spice Baby restaurant has 4 stars rating.                   ✖\n",
      "Poutine Palace restaurant has 3 stars rating.                     ✖\n",
      "Waffle Warriors restaurant has 3 stars rating.                    ✖\n",
      "Casablanca Café restaurant has 1 stars rating.                    ✖\n",
      "The Vodka Vault restaurant has 5 stars rating.                    ✖\n",
      "The Fish Fryer restaurant has 5 stars rating.                     ✖\n",
      "Baguette About It restaurant has 1 stars rating.                  ✖\n",
      "Taco 'Bout Tasty restaurant has 5 stars rating.                   ✖\n",
      "Curry Flurry restaurant has 3 stars rating.                       ✖\n",
      "Rib Ticklers BBQ restaurant has 4 stars rating.                   ✖\n",
      "Pho Real restaurant has 4 stars rating.                           ✖\n",
      "Tapas Time restaurant has 2 stars rating.                         ✖\n",
      "Tater Tot Tavern restaurant has 1 stars rating.                   ✖\n",
      "Ravioli Rumble restaurant has 3 stars rating.                     ✖\n",
      "Smorgasbord Smiles restaurant has 4 stars rating.                 ✖\n",
      "Jerk Chicken Junction restaurant has 4 stars rating.              ✖\n",
      "Ouzo Oomph restaurant has 6 stars rating.                         ✖\n",
      "Kilted Kuisine restaurant has 6 stars rating.                     ✖\n",
      "Pierogi Palace restaurant has 4 stars rating.                     ✖\n",
      "Fon-Do or Fon-Don't restaurant has 5 stars rating.                ✖\n",
      "Seoul Food restaurant has 3 stars rating.                         ✖\n",
      "Falafel Funnies restaurant has 5 stars rating.                    ✖\n",
      "Flapjack Fiesta restaurant has 5 stars rating.                    ✖\n",
      "Lucky Leprechaun Pub restaurant has 2 stars rating.               ✖\n",
      "Fiesta Fiesta restaurant has 6 stars rating.                      ✖\n",
      "Ceviche Circus restaurant has 5 stars rating.                     ✖\n",
      "The Catchy Cod restaurant has 4 stars rating.                     ✖\n",
      "Noodle Nook restaurant has 5 stars rating.                        ✖\n",
      "Salsa and Samba restaurant has 3 stars rating.                    ✖\n",
      "The Buttered Bagel restaurant has 3 stars rating.                 ✖\n",
      "Danish Delight restaurant has 2 stars rating.                     ✖\n",
      "Sahara Sandwiches restaurant has 1 stars rating.                  ✖\n",
      "Down Under Diner restaurant has 4 stars rating.                   ✖\n",
      "Masala Magic restaurant has 4 stars rating.                       ✖\n",
      "Goulash Galore restaurant has 1 stars rating.                     ✖\n",
      "Codfather Fishery restaurant has 6 stars rating.                  ✖\n",
      "Jerk and Twirl restaurant has 1 stars rating.                     ✖\n",
      "The Fez Food Fest restaurant has 2 stars rating.                  ✖\n",
      "Northern Lights Nosh restaurant has 3 stars rating.               ✖\n",
      "Mirage Munchies restaurant has 4 stars rating.                    ✖\n",
      "Balkan Bites restaurant has 5 stars rating.                       ✖\n",
      "Count Dracula’s Diner restaurant has 1 stars rating.              ✖\n",
      "Mandalay Munchies restaurant has 1 stars rating.                  ✖\n",
      "Java Jive Café restaurant has 6 stars rating.                     ✖\n",
      "Adriatic Appetites restaurant has 6 stars rating.                 ✖\n",
      "The Tropic Taste restaurant has 5 stars rating.                   ✖\n",
      "Mango Mania restaurant has 4 stars rating.                        ✖\n",
      "Tofu Tango restaurant has 3 stars rating.                         ✖\n",
      "Safari Snacks restaurant has 5 stars rating.                      ✖\n",
      "Bamboo Bistro restaurant has 3 stars rating.                      ✖\n",
      "Luxe Lunches restaurant has 3 stars rating.                       ✖\n",
      "The Casbah Café restaurant has 1 stars rating.                    ✖\n",
      "Knights and Noodles restaurant has 3 stars rating.                ✖\n",
      "Caribana Café restaurant has 4 stars rating.                      ✖\n",
      "Olive Orchard Eatery restaurant has 5 stars rating.               ✖\n",
      "Biryani Bliss restaurant has 4 stars rating.                      ✖\n",
      "Kigali Kitchen restaurant has 1 stars rating.                     ✖\n",
      "Salsa Fiesta restaurant has 5 stars rating.                       ✖\n",
      "Savory Safari restaurant has 4 stars rating.                      ✖\n",
      "Nile Nibbles restaurant has 6 stars rating.                       ✖\n",
      "Serengeti Snacks restaurant has 3 stars rating.                   ✖\n",
      "Ugandan Yum Yum restaurant has 2 stars rating.                    ✖\n",
      "BBQ Bonanza restaurant has 2 stars rating.                        ✖\n",
      "Uzbek Utopias restaurant has 2 stars rating.                      ✖\n",
      "Caracas Crunch restaurant has 1 stars rating.                     ✖\n",
      "Yemeni Yum restaurant has 3 stars rating.                         ✖\n",
      "Zany Zambia restaurant has 4 stars rating.                        ✖\n",
      "Zesty Zimbabwe restaurant has 6 stars rating.                     ✖\n",
      "Damascus Dine-In restaurant has 4 stars rating.                   ✖\n",
      "Togo Tacos restaurant has 1 stars rating.                         ✖\n",
      "Trinidad Treats restaurant has 2 stars rating.                    ✖\n",
      "Udon Believe It restaurant has 2 stars rating.                    ✖\n",
      "Vietnamese Vibes restaurant has 1 stars rating.                   ✖\n",
      "Welsh Rare-Bits restaurant has 6 stars rating.                    ✖\n",
      "Burrito Bandito restaurant has 1 stars rating.                    ✖\n",
      "Yummy Yucatan restaurant has 6 stars rating.                      ✖\n"
     ]
    }
   ],
   "source": [
    "for c, h in zip(candidate_sentences, is_hit):\n",
    "    print(f\"{c:60}  {hit_to_emoji[h]:>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Show me restaurants with at least 7 stars rating\n",
      "\n",
      "Rank  1: Adriatic Appetites restaurant has 6 stars rating.             0.72   ✖\n",
      "Rank  2: Oui, Chef! restaurant has 10 stars rating.                    0.72   ✅\n",
      "Rank  3: Wok This Way restaurant has 4 stars rating.                   0.72   ✖\n",
      "Rank  4: Grillin' & Chillin' restaurant has 5 stars rating.            0.72   ✖\n",
      "Rank  5: Curry Up Now restaurant has 8 stars rating.                   0.72   ✅\n",
      "Rank  6: The Souvlaki Shack restaurant has 10 stars rating.            0.71   ✅\n",
      "Rank  7: Holy Cannoli! restaurant has 8 stars rating.                  0.71   ✅\n",
      "Rank  8: The Fish Fryer restaurant has 5 stars rating.                 0.71   ✖\n",
      "Rank  9: Carnivore Carnival restaurant has 9 stars rating.             0.71   ✅\n",
      "Rank 10: Fon-Do or Fon-Don't restaurant has 5 stars rating.            0.71   ✖\n",
      "\n",
      "P@10: 0.50\n",
      "R@10: 0.50\n"
     ]
    }
   ],
   "source": [
    "debug = True\n",
    "\n",
    "# encode the text query and candidate\n",
    "query_embedding = model.encode(query_sentence).reshape(1, -1)\n",
    "candidate_embeddings = model.encode(candidate_sentences)\n",
    "\n",
    "# L2 normalize the embeddings\n",
    "faiss.normalize_L2(query_embedding)\n",
    "faiss.normalize_L2(candidate_embeddings)\n",
    "\n",
    "# compute the cosine similarity using FAISS\n",
    "d = model.get_sentence_embedding_dimension()\n",
    "\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(candidate_embeddings)\n",
    "\n",
    "k = 10\n",
    "D, I = index.search(query_embedding, k)\n",
    "\n",
    "\n",
    "# print the result\n",
    "# print query \n",
    "print(f\"Query: {query_sentence}\", end=\"\\n\\n\")\n",
    "\n",
    "if debug:\n",
    "    for i in range(k):\n",
    "        retrieved_sentence = candidate_sentences[I[0][i]]\n",
    "        hit_or_not = is_hit[I[0][i]]\n",
    "        print(f\"Rank {i+1:>2}: {retrieved_sentence:60} {D[0][i]:>5.2f} \", end=\"\")\n",
    "        print(f\"{hit_to_emoji[hit_or_not]:>3}\")\n",
    "\n",
    "# compute precision and recall at 10\n",
    "precision_at_10 = sum([is_hit[i] for i in list(I[0][:10])]) / 10\n",
    "recall_at_10 = sum([is_hit[i] for i in list(I[0][:10])]) / sum(is_hit)\n",
    "\n",
    "print()\n",
    "print(f\"P@10: {precision_at_10:.2f}\")\n",
    "print(f\"R@10: {recall_at_10:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
